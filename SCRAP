import requests
from bs4 import BeautifulSoup

BASE_URL = "http://nahoradoocio.lowlevel.com.br/"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
}

def scrape_site():
    try:
        response = requests.get(BASE_URL, headers=HEADERS, timeout=10)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"Erro ao acessar {BASE_URL}: {e}")
        return
    
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Coleta links
    links = [(link.get_text(strip=True), link["href"].strip()) for link in soup.find_all("a", href=True) if link["href"].startswith("http")]
    for text, href in links:
        print(f'Link encontrado: {href} - Texto: {text}')
        # Aqui, você pode chamar a função de inserção de dados no banco, se necessário.
    
    # Coleta parágrafos
    paragraphs = [p.get_text(strip=True) for p in soup.find_all("p") if p.get_text(strip=True)]
    for content in paragraphs:
        print(f'Parágrafo: {content}')
        # Aqui, você pode chamar a função de inserção de dados no banco, se necessário.

if __name__ == "__main__":
    scrape_site()
